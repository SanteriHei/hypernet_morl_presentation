<p><span class="citation" data-cites="roijers_survey_2013">[1]</span>
<span class="citation" data-cites="hayes_practical_2022">[2]</span>
<span class="citation" data-cites="chen_meta-learning_2019">[3]</span>
<span class="citation" data-cites="chauhan_brief_2024">[4]</span> <span
class="citation" data-cites="lu_multi_objective_2023">[5]</span> <span
class="citation" data-cites="sarafian_recomposing_2021">[6]</span> <span
class="citation" data-cites="xu_prediction_guided_2020">[7]</span> <span
class="citation" data-cites="alegre_sample_efficient_2023">[8]</span>
<span class="citation" data-cites="zintgraf_utility_2015">[9]</span>
<span class="citation" data-cites="zitzler_quality_2008">[10]</span>
<span class="citation"
data-cites="ishibuchi_modified_2015">[11]</span></p>
<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-roijers_survey_2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">D.
M. Roijers, P. Vamplew, S. Whiteson, and R. Dazeley, <span>“A survey of
multi-objective sequential decision-making,”</span> <em>Journal of
Artificial Intelligence Research</em>, vol. 48, 2013.</div>
</div>
<div id="ref-hayes_practical_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">C.
F. Hayes <em>et al.</em>, <span>“A practical guide to multi-objective
reinforcement learning and planning,”</span> <em>Autonomous Agents and
Multi-Agent Systems</em>, vol. 36, no. 1, 2022.</div>
</div>
<div id="ref-chen_meta-learning_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">X.
Chen, A. Ghadirzadeh, M. Björkman, and P. Jensfelt, <span>“Meta-learning
for multi-objective reinforcement learning,”</span> in <em>2019 IEEE/RSJ
international conference on intelligent robots and systems (IROS)</em>,
2019.</div>
</div>
<div id="ref-chauhan_brief_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">V.
K. Chauhan, J. Zhou, P. Lu, S. Molaei, and D. A. Clifton, <span>“A brief
review of hypernetworks in deep learning,”</span> <em>Artificial
Intelligence Review</em>, vol. 57, no. 6, 2024.</div>
</div>
<div id="ref-lu_multi_objective_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">H.
Lu, D. Herman, and Y. Yu, <span>“Multi-objective reinforcement learning:
Convexity, stationarity and pareto optimality,”</span> in <em>The
eleventh international conference on learning representations</em>,
2023.</div>
</div>
<div id="ref-sarafian_recomposing_2021" class="csl-entry"
role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">E.
Sarafian, S. Keynan, and S. Kraus, <span>“Recomposing the reinforcement
learning building blocks with hypernetworks,”</span> in <em>Proceedings
of the 38th international conference on machine learning</em>,
2021.</div>
</div>
<div id="ref-xu_prediction_guided_2020" class="csl-entry"
role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">J.
Xu, Y. Tian, P. Ma, D. Rus, S. Sueda, and W. Matusik,
<span>“Prediction-guided multi-objective reinforcement learning for
continuous robot control,”</span> in <em>Proceedings of the 37th
international conference on machine learning</em>, 2020.</div>
</div>
<div id="ref-alegre_sample_efficient_2023" class="csl-entry"
role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">A.
B. Alegre Lucas N, D. M. Roijers, A. Nowé, and B. C. da Silva,
<span>“Sample-efficient multi-objective learning via generalized policy
improvement prioritization,”</span> in <em>AAMAS ’23: Proceedings of the
2023 international conference on autonomous agents and multiagent
systems</em>, 2023.</div>
</div>
<div id="ref-zintgraf_utility_2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">L.
M. Zintgraf, T. V. Kanters, D. M. Roijers, F. Oliehoek, and P. Beau,
<span>“Quality assessment of MORL algorithms: A utility-based
approach,”</span> in <em>Benelearn 2015: Proceedings of the 24th annual
machine learning conference of belgium and the netherlands</em>,
2015.</div>
</div>
<div id="ref-zitzler_quality_2008" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">E.
Zitzler, J. Knowles, and L. Thiele, <span>“Quality assessment of pareto
set approximations,”</span> in <em>Multiobjective optimization:
Interactive and evolutionary approaches</em>, Springer, 2008.</div>
</div>
<div id="ref-ishibuchi_modified_2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">H.
Ishibuchi, H. Masuda, Y. Tanigaki, and Y. Nojima, <span>“Modified
distance calculation in generational distance and inverted generational
distance,”</span> in <em>Evolutionary multi-criterion optimization</em>,
2015.</div>
</div>
</div>
